# ğŸš€ Demonology Quick Start Guide

Get up and running with ultra-stable llama server sessions in 2 minutes.

## âš¡ **Quick Launch** (Recommended)

### Terminal 1: Start Server
```bash
cd /home/k/Desktop/Demonology
./llama-server-nosudo.sh
```
Wait for: `server is listening on http://0.0.0.0:8080`

### Terminal 2: Launch Demonology  
```bash
demonology
```

**That's it!** ğŸ‰ You now have:
- âœ… Ultra-stable server with auto-restart
- âœ… Intelligent context management
- âœ… 26768 token context (matches your server)
- âœ… Dual GPU optimization (RTX 5080 + RTX 3060)

---

## ğŸ”„ **Alternative: Fully Automated**

**One command for everything:**
```bash
./auto-restart-server.sh
```
This will:
- Start the llama server
- Launch Demonology automatically  
- Monitor and restart on crashes
- Handle VRAM clearing

---

## ğŸ“‹ **Essential Commands**

| Command | Description |
|---------|-------------|
| `/help` | Show all available commands |
| `/context` | Show context usage (with color warnings) |
| `/optimize` | Smart context optimization |
| `/restart` | Manual server restart + VRAM clear |
| `/trim smart` | Intelligent message trimming |
| `/quit` | Exit Demonology |

---

## ğŸ”§ **Troubleshooting**

### Server Won't Start?
```bash
# Check if port 8080 is in use
sudo netstat -tulpn | grep 8080

# Kill existing servers
pkill -f llama-server

# Try again
./llama-server-nosudo.sh
```

### Demonology Connection Issues?
1. **Auto-restart**: It will try to restart server automatically
2. **Manual restart**: Use `/restart` command within Demonology
3. **Check logs**: `tail -f /tmp/llama-server.log`

### Context Full Warnings?
- **Auto-handled**: Smart trimming at 85% usage
- **Manual control**: `/optimize` or `/trim smart`
- **Monitor**: `/context` shows detailed stats

---

## ğŸ“Š **What You Get**

### **Server Optimizations**
- ğŸ”„ Continuous batching for efficiency
- ğŸ’¾ Memory defragmentation (0.1 threshold)  
- âš¡ 8 parallel processing slots
- ğŸ§  NUMA isolation for GPU performance
- ğŸ¯ f16 cache types for memory efficiency

### **Client Features**
- ğŸ” 5x retry attempts with exponential backoff
- â±ï¸ 12-minute streaming timeouts (720s)
- ğŸ”— HTTP keep-alive connections (5min expiry)
- ğŸ’“ Heartbeat monitoring (120s timeout)
- ğŸ§  Smart context management (26768 tokens)

### **Auto-Recovery**
- ğŸš¨ Detects server crashes and 500 errors
- ğŸ”„ Automatic server restart with VRAM clearing
- ğŸ“Š Real-time context monitoring with warnings
- ğŸ’¾ Intelligent message preservation during trimming

---

## ğŸ¯ **Pro Tips**

1. **Monitor context**: Use `/context` regularly to see usage
2. **Long sessions**: Let smart trimming handle context automatically
3. **GPU memory**: Server clears VRAM on restart automatically
4. **Performance**: Use the dual-terminal setup for best results
5. **Logs**: Check `/tmp/llama-server.log` for server issues

---

**Need help?** Check `STABILITY.md` for detailed technical information.